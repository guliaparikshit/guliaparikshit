{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QS9kKPNPkftp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q1: Define overfitting and underfitting in machine learning. What are the consequences of each, and how\n",
        "can they be mitigated?"
      ],
      "metadata": {
        "id": "pdlyZzdvkw97"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J5NhELLbkxMf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Overfitting occurs when the model learns the details and noise in the training data too well, causing poor performance on new, unseen data.\n",
        "\n",
        "Consequences: High accuracy on training data but low accuracy on test data.\n",
        "\n",
        "Mitigation: Use simpler models, gather more data, or apply regularization techniques.\n",
        "\n",
        "Underfitting happens when the model is too simple to capture the underlying patterns in the data.\n",
        "\n",
        "Consequences: Poor performance on both training and test data.\n",
        "\n",
        "Mitigation: Use more complex models or improve feature selection."
      ],
      "metadata": {
        "id": "myeZhN8jkzV4"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ow3s1JRmk26f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q2: How can we reduce overfitting? Explain in brief."
      ],
      "metadata": {
        "id": "ufA9KQnLk4hY"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BU63fsrtk4zX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use cross-validation to tune hyperparameters.\n",
        "\n",
        "Apply regularization (e.g., L1/L2 regularization).\n",
        "\n",
        "Prune decision trees or reduce model complexity.\n",
        "\n",
        "Increase training data or use data augmentation."
      ],
      "metadata": {
        "id": "JGr69FGak7S-"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P6DZt7Xgk9J2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q3: Explain underfitting. List scenarios where underfitting can occur in ML."
      ],
      "metadata": {
        "id": "XwT126elk-1t"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rN_gFmk6k_Fi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Underfitting happens when the model is too simple to capture the data's underlying patterns.\n",
        "\n",
        "Scenarios:\n",
        "\n",
        "Using a linear model for non-linear data.\n",
        "\n",
        "Having too few features to represent the data adequately.\n",
        "\n",
        "Training for too few iterations in complex models like neural networks."
      ],
      "metadata": {
        "id": "65vCiMUKlBvM"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rVkviY79lDZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q4: Explain the bias-variance tradeoff in machine learning. What is the relationship between bias and\n",
        "variance, and how do they affect model performance?"
      ],
      "metadata": {
        "id": "RLbC-8w6lFFQ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MRN3hg6-lFS5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The bias-variance tradeoff describes the balance between model simplicity and complexity.\n",
        "\n",
        "Bias refers to errors from overly simplistic models (underfitting).\n",
        "\n",
        "Variance refers to errors from overly complex models (overfitting).\n",
        "\n",
        "The goal is to minimize both bias and variance to achieve the best model performance.\n"
      ],
      "metadata": {
        "id": "myIpp8AblHlh"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VKdiiaHOlItW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q5: Discuss some common methods for detecting overfitting and underfitting in machine learning models.\n",
        "How can you determine whether your model is overfitting or underfitting?"
      ],
      "metadata": {
        "id": "wREtJ6KKlKcO"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yoFA43trlKtJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Overfitting is detected when the model performs well on training data but poorly on validation or test data.\n",
        "\n",
        "Underfitting is detected when the model performs poorly on both training and test data.\n",
        "\n",
        "Methods include:\n",
        "Learning curves (plot training and validation error over time)"
      ],
      "metadata": {
        "id": "KnPfgCtzlOc2"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "guUqnbwylPwn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q6: Compare and contrast bias and variance in machine learning. What are some examples of high bias\n",
        "and high variance models, and how do they differ in terms of their performance?"
      ],
      "metadata": {
        "id": "FUiyp0IvlS0y"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CQ2MA8fglTER"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "High Bias (Underfitting): The model makes strong assumptions and is too simple. Example: A linear model for non-linear data.\n",
        "\n",
        "High Variance (Overfitting): The model is too complex and fits noise.\n",
        "Example: A deep neural network with too many layers.\n",
        "\n",
        "Difference in performance: High bias leads to poor performance on both training and test data. High variance leads to excellent performance on training data but poor performance on test data."
      ],
      "metadata": {
        "id": "07L3mx9KlVX2"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TEIQNbcKlZp0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q7: What is regularization in machine learning, and how can it be used to prevent overfitting? Describe\n",
        "some common regularization techniques and how they work."
      ],
      "metadata": {
        "id": "0qyf8zLilct8"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LST8JXculc7y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Regularization adds a penalty term to the modelâ€™s loss function to prevent it from becoming too complex and overfitting.\n",
        "Common techniques include:\n",
        "\n",
        "L1 Regularization (Lasso): Adds the sum of absolute values of coefficients as a penalty.\n",
        "\n",
        "L2 Regularization (Ridge): Adds the sum of squared coefficients as a penalty.\n",
        "\n",
        "Dropout (in neural networks): Randomly drops some units during training to reduce dependence on specific nodes."
      ],
      "metadata": {
        "id": "NmRUv9ZjlfEn"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eRWzJAnxlhED"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}